{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory configuration should be consistent and optimized\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.8\"  # More conservative than 1.0\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"  # Enable for better memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/myp23/env/lib/python3.10/site-packages/gwpy/time/__init__.py:36: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(False)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  from lal import LIGOTimeGPS\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import blackjax\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.time import Time\n",
    "import tqdm\n",
    "\n",
    "# Enable 64-bit precision early\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "# Import detector and likelihood functions\n",
    "from jimgw.single_event.detector import H1, L1, V1\n",
    "from jimgw.single_event.likelihood import original_likelihood as likelihood_function\n",
    "from jimgw.single_event.likelihood import phase_marginalized_likelihood as likelihood_function_phase_marginalized\n",
    "from jimgw.single_event.waveform import RippleIMRPhenomD\n",
    "\n",
    "# Initialize waveform once\n",
    "waveform = RippleIMRPhenomD(f_ref=50)\n",
    "\n",
    "# Constants for noise curves\n",
    "ASD_PATHS = {\n",
    "    \"H1\": \"/mnt/data/myp23/env/lib/python3.10/site-packages/bilby/gw/detector/noise_curves/aLIGO_O4_high_asd.txt\",\n",
    "    \"L1\": \"/mnt/data/myp23/env/lib/python3.10/site-packages/bilby/gw/detector/noise_curves/aLIGO_O4_high_asd.txt\", \n",
    "    \"V1\": \"/mnt/data/myp23/env/lib/python3.10/site-packages/bilby/gw/detector/noise_curves/AdV_asd.txt\",\n",
    "}\n",
    "\n",
    "# Pre-compute injection parameters as JAX arrays\n",
    "INJECTION_PARAMS = {\n",
    "    \"M_c\": jnp.array(28.588),  # Pre-computed chirp mass\n",
    "    \"q\": jnp.array(0.806),     # Pre-computed mass ratio\n",
    "    \"s1_z\": jnp.array(0.4),\n",
    "    \"s2_z\": jnp.array(-0.3),   # Negative due to tilt_2=Ï€\n",
    "    \"d_L\": jnp.array(2000.0),\n",
    "    \"iota\": jnp.array(0.4),\n",
    "    \"t_c\": jnp.array(0.0),\n",
    "    \"phase_c\": jnp.array(1.3),\n",
    "    \"ra\": jnp.array(1.375),\n",
    "    \"dec\": jnp.array(-1.2108),\n",
    "    \"psi\": jnp.array(2.659),\n",
    "    #\"gmst\": jnp.array(1.7539),  # Pre-computed GMST\n",
    "    \"eta\": jnp.array(0.246),    # Pre-computed symmetric mass ratio\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded detector data as JAX arrays: <class 'jaxlib.xla_extension.ArrayImpl'>\n"
     ]
    }
   ],
   "source": [
    "# Load detector data efficiently as JAX arrays\n",
    "DETECTOR_DATA = {\n",
    "    'frequencies': jnp.array(np.load('debug_frequency_array.npy')),\n",
    "    'H1': jnp.array(np.load('debug_H1_data.npy')),\n",
    "    'L1': jnp.array(np.load('debug_L1_data.npy')),\n",
    "    'V1': jnp.array(np.load('debug_V1_data.npy'))\n",
    "}\n",
    "\n",
    "print(f\"Loaded detector data as JAX arrays: {type(DETECTOR_DATA['frequencies'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured 3 detectors with 16225 frequency points\n",
      "H1.frequencies type: <class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "H1.data type: <class 'jaxlib.xla_extension.ArrayImpl'>\n"
     ]
    }
   ],
   "source": [
    "# Configure detector frequency range efficiently\n",
    "FREQ_RANGE = {'min': 20.0, 'max': 2048.0}\n",
    "\n",
    "# Vectorized frequency mask calculation\n",
    "freq_mask = (DETECTOR_DATA['frequencies'] >= FREQ_RANGE['min']) & (DETECTOR_DATA['frequencies'] <= FREQ_RANGE['max'])\n",
    "filtered_frequencies = DETECTOR_DATA['frequencies'][freq_mask]\n",
    "\n",
    "# Configure detectors using vectorized operations\n",
    "detectors = [H1, L1, V1]\n",
    "detector_names = ['H1', 'L1', 'V1']\n",
    "\n",
    "# Vectorized detector configuration\n",
    "for det, name in zip(detectors, detector_names):\n",
    "    det.frequencies = filtered_frequencies  \n",
    "    det.data = DETECTOR_DATA[name][freq_mask]\n",
    "\n",
    "print(f\"Configured {len(detectors)} detectors with {len(filtered_frequencies)} frequency points\")\n",
    "\n",
    "# Verify JAX arrays are preserved\n",
    "print(f\"H1.frequencies type: {type(H1.frequencies)}\")\n",
    "print(f\"H1.data type: {type(H1.data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1.psd type: <class 'jaxlib.xla_extension.ArrayImpl'>\n",
      "PSD shape: (16225,)\n"
     ]
    }
   ],
   "source": [
    "# Pre-load and vectorize PSD data for all detectors\n",
    "def load_psd_data(asd_paths):\n",
    "    \"\"\"Load ASD data for all detectors and convert to PSD.\"\"\"\n",
    "    psd_data = {}\n",
    "    for name, path in asd_paths.items():\n",
    "        f_np, asd_vals_np = np.loadtxt(path, unpack=True)\n",
    "        psd_data[name] = {\n",
    "            'frequencies': jnp.array(f_np),\n",
    "            'psd': jnp.array(asd_vals_np**2)  # Convert ASD to PSD\n",
    "        }\n",
    "    return psd_data\n",
    "\n",
    "# Load all PSD data once\n",
    "PSD_DATA = load_psd_data(ASD_PATHS)\n",
    "\n",
    "# Vectorized PSD interpolation for all detectors\n",
    "@jax.jit\n",
    "def interpolate_psd(det_frequencies, psd_frequencies, psd_values):\n",
    "    \"\"\"JAX-compiled PSD interpolation.\"\"\"\n",
    "    return jnp.interp(det_frequencies, psd_frequencies, psd_values)\n",
    "\n",
    "# Configure detector PSDs using vectorized operations\n",
    "for det in detectors:\n",
    "    det.psd = interpolate_psd(\n",
    "        det.frequencies,\n",
    "        PSD_DATA[det.name]['frequencies'],\n",
    "        PSD_DATA[det.name]['psd']\n",
    "    )\n",
    "\n",
    "# Verify PSD arrays are JAX arrays\n",
    "print(f\"H1.psd type: {type(H1.psd)}\")\n",
    "print(f\"PSD shape: {H1.psd.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling over 10 parameters: ['M_c', 'q', 's1_z', 's2_z', 'iota', 'd_L', 't_c', 'psi', 'ra', 'dec']\n",
      "Wraparound parameters: ['psi', 'ra']\n",
      "Wraparound array: [False False False False False False False  True  True False]\n",
      "Wraparound angles: [1.         1.         1.         1.         1.\n",
      " 1.         1.         3.14159265 6.28318531 1.        ]\n",
      "Using PHASE MARGINALIZED LIKELIHOOD - phase_c excluded from sampling\n"
     ]
    }
   ],
   "source": [
    "# Define which parameters to sample over - ALL EXCEPT phase_c for phase marginalization\n",
    "SAMPLE_KEYS = [\"M_c\", \"q\", \"s1_z\", \"s2_z\", \"iota\", \"d_L\", \"t_c\", \"psi\", \"ra\", \"dec\"]  # Exclude phase_c\n",
    "\n",
    "# All possible parameters and their properties\n",
    "ALL_PARAM_CONFIG = {\n",
    "    \"M_c\": {\"min\": 20.0, \"max\": 40.0, \"prior\": \"uniform\", \"wraparound\": False, \"angle\": 1.0},\n",
    "    \"q\": {\"min\": 0.25, \"max\": 1.0, \"prior\": \"uniform\", \"wraparound\": False, \"angle\": 1.0},\n",
    "    \"s1_z\": {\"min\": -1.0, \"max\": 1.0, \"prior\": \"uniform\", \"wraparound\": False, \"angle\": 1.0},\n",
    "    \"s2_z\": {\"min\": -1.0, \"max\": 1.0, \"prior\": \"uniform\", \"wraparound\": False, \"angle\": 1.0},\n",
    "    \"iota\": {\"min\": 0.0, \"max\": jnp.pi, \"prior\": \"sine\", \"wraparound\": False, \"angle\": 1.0},\n",
    "    \"d_L\": {\"min\": 100.0, \"max\": 5000.0, \"prior\": \"beta\", \"wraparound\": False, \"angle\": 1.0},\n",
    "    \"t_c\": {\"min\": -0.1, \"max\": 0.1, \"prior\": \"uniform\", \"wraparound\": False, \"angle\": 1.0},\n",
    "    \"phase_c\": {\"min\": 0.0, \"max\": 2*jnp.pi, \"prior\": \"uniform\", \"wraparound\": True, \"angle\": 2*jnp.pi},\n",
    "    \"psi\": {\"min\": 0.0, \"max\": jnp.pi, \"prior\": \"uniform\", \"wraparound\": True, \"angle\": jnp.pi},\n",
    "    \"ra\": {\"min\": 0.0, \"max\": 2*jnp.pi, \"prior\": \"uniform\", \"wraparound\": True, \"angle\": 2*jnp.pi},\n",
    "    \"dec\": {\"min\": -jnp.pi/2, \"max\": jnp.pi/2, \"prior\": \"cosine\", \"wraparound\": False, \"angle\": 1.0},\n",
    "}\n",
    "\n",
    "# Extract configuration for sampled parameters only\n",
    "SAMPLED_CONFIG = {key: ALL_PARAM_CONFIG[key] for key in SAMPLE_KEYS}\n",
    "n_dims = len(SAMPLE_KEYS)\n",
    "\n",
    "# Pre-compute vectorized arrays for GPU efficiency\n",
    "PARAM_MINS = jnp.array([SAMPLED_CONFIG[key][\"min\"] for key in SAMPLE_KEYS])\n",
    "PARAM_MAXS = jnp.array([SAMPLED_CONFIG[key][\"max\"] for key in SAMPLE_KEYS])\n",
    "PARAM_PRIOR_TYPES = jnp.array([\n",
    "    0 if SAMPLED_CONFIG[key][\"prior\"] == \"uniform\" else\n",
    "    1 if SAMPLED_CONFIG[key][\"prior\"] == \"sine\" else\n",
    "    2 if SAMPLED_CONFIG[key][\"prior\"] == \"cosine\" else\n",
    "    3 for key in SAMPLE_KEYS  # beta\n",
    "])\n",
    "\n",
    "# CRITICAL FIX: Use SAMPLE_KEYS order consistently (not sorted keys)\n",
    "# This ensures wraparound arrays match the parameter order used throughout\n",
    "wraparound = jnp.array([SAMPLED_CONFIG[key][\"wraparound\"] for key in SAMPLE_KEYS])\n",
    "wraparound_angle = jnp.array([SAMPLED_CONFIG[key][\"angle\"] for key in SAMPLE_KEYS])\n",
    "\n",
    "print(f\"Sampling over {n_dims} parameters: {SAMPLE_KEYS}\")\n",
    "print(f\"Wraparound parameters: {[key for key in SAMPLE_KEYS if SAMPLED_CONFIG[key]['wraparound']]}\")\n",
    "print(f\"Wraparound array: {wraparound}\")\n",
    "print(f\"Wraparound angles: {wraparound_angle}\")\n",
    "print(\"Using PHASE MARGINALIZED LIKELIHOOD - phase_c excluded from sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up constants for likelihood computation\n",
    "post_trigger_duration = 2\n",
    "duration = 8\n",
    "epoch = duration - post_trigger_duration\n",
    "gmst = Time(1126259642.413, format=\"gps\").sidereal_time(\"apparent\", \"greenwich\").rad\n",
    "frequencies = H1.frequencies\n",
    "\n",
    "# Column labels for plotting\n",
    "column_to_label = {\n",
    "    \"M_c\": r\"$M_c$\",\n",
    "    \"q\": r\"$q$\",\n",
    "    \"d_L\": r\"$d_L$\",\n",
    "    \"iota\": r\"$\\iota$\",\n",
    "    \"ra\": r\"$\\alpha$\",\n",
    "    \"dec\": r\"$\\delta$\",\n",
    "    \"s1_z\": r\"$s_{1z}$\",\n",
    "    \"s2_z\": r\"$s_{2z}$\",\n",
    "    \"t_c\": r\"$t_c$\",\n",
    "    \"psi\": r\"$\\psi$\",\n",
    "    \"phase_c\": r\"$\\phi_c$\",\n",
    "}\n",
    "\n",
    "# Vectorized prior functions\n",
    "@jax.jit\n",
    "def vectorized_uniform_logprob(x, a, b):\n",
    "    return jnp.where((x >= a) & (x <= b), -jnp.log(b - a), -jnp.inf)\n",
    "\n",
    "@jax.jit\n",
    "def vectorized_sine_logprob(x):\n",
    "    return jnp.where((x >= 0.0) & (x <= jnp.pi), jnp.log(jnp.sin(x) / 2.0), -jnp.inf)\n",
    "\n",
    "@jax.jit\n",
    "def vectorized_cosine_logprob(x):\n",
    "    return jnp.where(jnp.abs(x) < jnp.pi / 2, jnp.log(jnp.cos(x) / 2.0), -jnp.inf)\n",
    "\n",
    "@jax.jit\n",
    "def vectorized_beta_logprob(x, a, b):\n",
    "    u = (x - a) / (b - a)\n",
    "    logpdf = (2.0 * jnp.log(u) + 0.0 * jnp.log(1 - u) - jax.scipy.special.betaln(3.0, 1.0) - jnp.log(b - a))\n",
    "    return jnp.where((x >= a) & (x <= b), logpdf, -jnp.inf)\n",
    "\n",
    "@jax.jit\n",
    "def loglikelihood_fn(params):\n",
    "    \"\"\"Phase marginalized likelihood function - sets phase_c=0.\"\"\"\n",
    "    # Start with injection parameters and update with sampled parameters\n",
    "    p = INJECTION_PARAMS.copy()\n",
    "    p.update(params)  # JAX-compatible dictionary update\n",
    "    \n",
    "    # CRITICAL: Set phase_c = 0 for phase marginalized likelihood\n",
    "    p[\"phase_c\"] = 0.0\n",
    "    \n",
    "    # Use dynamically calculated gmst instead of hardcoded value\n",
    "    p[\"gmst\"] = gmst\n",
    "    \n",
    "    # Always calculate this\n",
    "    p[\"eta\"] = p[\"q\"] / (1 + p[\"q\"]) ** 2\n",
    "    \n",
    "    waveform_sky = waveform(filtered_frequencies, p)\n",
    "    align_time = jnp.exp(-1j * 2 * jnp.pi * filtered_frequencies * (epoch + p[\"t_c\"]))\n",
    "    \n",
    "    # Use phase marginalized likelihood function\n",
    "    return likelihood_function_phase_marginalized(p, waveform_sky, detectors, filtered_frequencies, align_time)\n",
    "\n",
    "@jax.jit\n",
    "def logprior_fn(params):\n",
    "    \"\"\"Fully vectorized prior function - no loops.\"\"\"\n",
    "    # Extract parameter values in consistent order\n",
    "    param_values = jnp.array([params[key] for key in SAMPLE_KEYS])\n",
    "    \n",
    "    # Compute all prior types vectorially\n",
    "    uniform_priors = vectorized_uniform_logprob(param_values, PARAM_MINS, PARAM_MAXS)\n",
    "    sine_priors = vectorized_sine_logprob(param_values)\n",
    "    cosine_priors = vectorized_cosine_logprob(param_values)\n",
    "    beta_priors = vectorized_beta_logprob(param_values, PARAM_MINS, PARAM_MAXS)\n",
    "    \n",
    "    # Select appropriate prior for each parameter using vectorized operations\n",
    "    priors = jnp.where(\n",
    "        PARAM_PRIOR_TYPES == 0, uniform_priors,\n",
    "        jnp.where(\n",
    "            PARAM_PRIOR_TYPES == 1, sine_priors,\n",
    "            jnp.where(\n",
    "                PARAM_PRIOR_TYPES == 2, cosine_priors,\n",
    "                beta_priors\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return jnp.sum(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized 1000 particles for parameters: ['M_c', 'q', 's1_z', 's2_z', 'iota', 'd_L', 't_c', 'psi', 'ra', 'dec']\n",
      "Created unravel function once (prevents recompilation)\n",
      "Ravel order: ['M_c', 'd_L', 'dec', 'iota', 'psi', 'q', 'ra', 's1_z', 's2_z', 't_c']\n",
      "Wraparound array (ravel order): [False False False False  True False  True False False False]\n",
      "Wraparound angles (ravel order): [1.         1.         1.         1.         3.14159265\n",
      " 1.         6.28318531 1.         1.         1.        ]\n",
      "Wraparound config: {'psi': 3.141592653589793, 'ra': 6.283185307179586}\n",
      "âœ… Nested sampler initialized with recompilation-free, generic functions\n",
      "âœ… FIXED: Wraparound arrays now match ravel_pytree order exactly\n",
      "âœ… FIXED: Using efficient ravel_pytree with matching unravel_fn\n"
     ]
    }
   ],
   "source": [
    "# Nested sampling configuration\n",
    "n_live = 1000\n",
    "n_delete = int(n_live * 0.5)\n",
    "num_mcmc_steps = n_dims * 5\n",
    "\n",
    "# Sample live points only for parameters we're fitting\n",
    "rng_key = jax.random.PRNGKey(0)\n",
    "rng_key, init_key = jax.random.split(rng_key, 2)\n",
    "init_keys = jax.random.split(init_key, len(SAMPLE_KEYS))\n",
    "\n",
    "particles = {}\n",
    "for i, key in enumerate(SAMPLE_KEYS):\n",
    "    config = SAMPLED_CONFIG[key]\n",
    "    \n",
    "    if config[\"prior\"] == \"uniform\":\n",
    "        particles[key] = jax.random.uniform(\n",
    "            init_keys[i], (n_live,), minval=config[\"min\"], maxval=config[\"max\"]\n",
    "        )\n",
    "    elif config[\"prior\"] == \"sine\":\n",
    "        particles[key] = jnp.arccos(1 - 2 * jax.random.uniform(init_keys[i], (n_live,)))\n",
    "    elif config[\"prior\"] == \"cosine\":\n",
    "        particles[key] = jnp.arcsin(2 * jax.random.uniform(init_keys[i], (n_live,)) - 1)\n",
    "    elif config[\"prior\"] == \"beta\":\n",
    "        particles[key] = (jax.random.beta(init_keys[i], 3.0, 1.0, shape=(n_live,)) * \n",
    "                         (config[\"max\"] - config[\"min\"]) + config[\"min\"])\n",
    "\n",
    "print(f\"Initialized {n_live} particles for parameters: {list(particles.keys())}\")\n",
    "\n",
    "# âœ… CREATE UNRAVEL FUNCTION ONCE - FIXES RECOMPILATION ISSUE\n",
    "example_particle = jax.tree_util.tree_map(lambda x: x[0], particles)\n",
    "_, unravel_fn = jax.flatten_util.ravel_pytree(example_particle)\n",
    "print(\"Created unravel function once (prevents recompilation)\")\n",
    "\n",
    "# âœ… CRITICAL FIX: Determine the order that ravel_pytree uses and match wraparound arrays to it\n",
    "# This ensures wraparound arrays match the actual flattened parameter order\n",
    "def get_ravel_order(particles_dict):\n",
    "    \"\"\"Determine the order that ravel_pytree uses for flattening.\"\"\"\n",
    "    example = jax.tree_util.tree_map(lambda x: x[0], particles_dict)\n",
    "    flat, _ = jax.flatten_util.ravel_pytree(example)\n",
    "    \n",
    "    # Create a test dict with unique values to identify the order\n",
    "    test_dict = {key: float(i) for i, key in enumerate(particles_dict.keys())}\n",
    "    test_flat, _ = jax.flatten_util.ravel_pytree(test_dict)\n",
    "    \n",
    "    # The order is determined by the positions in the flattened array\n",
    "    order = []\n",
    "    for val in test_flat:\n",
    "        for key, test_val in test_dict.items():\n",
    "            if abs(val - test_val) < 1e-10:\n",
    "                order.append(key)\n",
    "                break\n",
    "    return order\n",
    "\n",
    "ravel_order = get_ravel_order(particles)\n",
    "print(f\"Ravel order: {ravel_order}\")\n",
    "\n",
    "# âœ… Create wraparound arrays in the SAME order as ravel_pytree uses\n",
    "wraparound_ravel_order = jnp.array([SAMPLED_CONFIG[key][\"wraparound\"] for key in ravel_order])\n",
    "wraparound_angle_ravel_order = jnp.array([SAMPLED_CONFIG[key][\"angle\"] for key in ravel_order])\n",
    "\n",
    "print(f\"Wraparound array (ravel order): {wraparound_ravel_order}\")\n",
    "print(f\"Wraparound angles (ravel order): {wraparound_angle_ravel_order}\")\n",
    "\n",
    "# âœ… GENERIC STEPPER FACTORY - FIXES RECOMPILATION AND BRITTLENESS\n",
    "def make_generic_stepper(wraparound_config):\n",
    "    \"\"\"Factory that creates a generic stepper function.\"\"\"\n",
    "    \n",
    "    @jax.jit\n",
    "    def stepper_fn(x, d, t):\n",
    "        # 1. Perform the standard linear step for all parameters\n",
    "        y_proposed = jax.tree_util.tree_map(lambda val, direction: val + t * direction, x, d)\n",
    "\n",
    "        # 2. Define the logic to apply wrapping conditionally\n",
    "        def wrap_leaf(path, leaf_val):\n",
    "            # For a dict, path will be a tuple like (KeyPath(key='psi'),)\n",
    "            key = path[0].key \n",
    "            if key in wraparound_config:\n",
    "                return jnp.mod(leaf_val, wraparound_config[key])\n",
    "            else:\n",
    "                return leaf_val\n",
    "\n",
    "        # 3. Apply the wrapping logic to the proposed tree\n",
    "        y_wrapped = jax.tree_util.tree_map_with_path(wrap_leaf, y_proposed)\n",
    "        \n",
    "        return y_wrapped\n",
    "\n",
    "    return stepper_fn\n",
    "\n",
    "# Create wraparound configuration from SAMPLED_CONFIG\n",
    "wraparound_config = {\n",
    "    key: SAMPLED_CONFIG[key][\"angle\"] \n",
    "    for key in SAMPLE_KEYS \n",
    "    if SAMPLED_CONFIG[key][\"wraparound\"]\n",
    "}\n",
    "print(f\"Wraparound config: {wraparound_config}\")\n",
    "\n",
    "# âœ… CREATE THE GENERIC STEPPER ONCE\n",
    "generic_stepper = make_generic_stepper(wraparound_config)\n",
    "\n",
    "# âœ… FACTORY FUNCTION FOR COVARIANCE CALCULATION - FIXES RECOMPILATION\n",
    "def make_calc_covmat_jax(unravel_fn, wraparound, wraparound_angle):\n",
    "    \"\"\"Factory function that creates the adaptation function with fixed unravel_fn.\"\"\"\n",
    "    \n",
    "    @jax.jit\n",
    "    def calc_covmat_jax_inner(state, info, inner_kernel_params):\n",
    "        \"\"\"Fast covariance calculation using ravel_pytree (efficient and standard).\"\"\"\n",
    "        # âœ… Use ravel_pytree - efficient and matches unravel_fn\n",
    "        x = jax.vmap(lambda p: jax.flatten_util.ravel_pytree(p)[0])(state.particles)\n",
    "        x = x / wraparound_angle  # Scale by angles - now in correct ravel order\n",
    "        \n",
    "        x = x.T\n",
    "        nDims, n = x.shape\n",
    "        \n",
    "        # Circular statistics only for wraparound parameters\n",
    "        sinpart = jnp.sum(jnp.sin(x * 2*jnp.pi), axis=1)\n",
    "        cospart = jnp.sum(jnp.cos(x * 2*jnp.pi), axis=1)\n",
    "        circle_mu_angular_part = jnp.atan2(sinpart, cospart) / (2*jnp.pi)\n",
    "        \n",
    "        circle_mu = jnp.where(wraparound, circle_mu_angular_part, 0.0)\n",
    "        circle_diff = x - circle_mu[:, jnp.newaxis]\n",
    "        circle_diff = circle_diff - jnp.round(circle_diff)\n",
    "        \n",
    "        circle_mu_refined = jnp.mod(jnp.sum(circle_diff, axis=1) / n + circle_mu, 1.0)\n",
    "        normal_diff = x - jnp.sum(x, axis=1)[:, jnp.newaxis] / n\n",
    "        circle_diff_refined = x - circle_mu_refined[:, jnp.newaxis]\n",
    "        wraparound_broadcast = wraparound[:, jnp.newaxis]\n",
    "        dx = jnp.where(wraparound_broadcast, circle_diff_refined - jnp.round(circle_diff_refined), normal_diff)\n",
    "        dx = dx * wraparound_angle[:, jnp.newaxis]\n",
    "        \n",
    "        cov_matrix = (dx @ dx.T) / (n - 1.0)\n",
    "        \n",
    "        # âœ… Use pre-computed unravel_fn (no recompilation) - now matches ravel order\n",
    "        cov_pytree = jax.vmap(unravel_fn)(cov_matrix)\n",
    "        return {\"cov\": cov_pytree}\n",
    "    \n",
    "    return calc_covmat_jax_inner\n",
    "\n",
    "# âœ… CREATE THE ADAPTATION FUNCTION with ravel-order wraparound arrays\n",
    "my_calc_covmat_fn = make_calc_covmat_jax(unravel_fn, wraparound_ravel_order, wraparound_angle_ravel_order)\n",
    "\n",
    "# Initialize the Nested Sampling algorithm\n",
    "nested_sampler = blackjax.nss(\n",
    "    logprior_fn=logprior_fn,\n",
    "    loglikelihood_fn=loglikelihood_fn,\n",
    "    num_delete=n_delete,\n",
    "    num_inner_steps=num_mcmc_steps,\n",
    "    stepper_fn=generic_stepper,  # âœ… Use the generic stepper\n",
    "    adapt_direction_params_fn=my_calc_covmat_fn,  # âœ… Use the pre-created function\n",
    ")\n",
    "\n",
    "state = nested_sampler.init(particles, logprior_fn=logprior_fn, loglikelihood_fn=loglikelihood_fn)\n",
    "\n",
    "@jax.jit\n",
    "def one_step(carry, xs):\n",
    "    state, k = carry\n",
    "    k, subk = jax.random.split(k, 2)\n",
    "    state, dead_point = nested_sampler.step(subk, state)\n",
    "    return (state, k), dead_point\n",
    "\n",
    "print(\"âœ… Nested sampler initialized with recompilation-free, generic functions\")\n",
    "print(\"âœ… FIXED: Wraparound arrays now match ravel_pytree order exactly\")\n",
    "print(\"âœ… FIXED: Using efficient ravel_pytree with matching unravel_fn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dead points: 0 dead points [00:00, ? dead points/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dead points: 22000 dead points [1:01:54,  5.92 dead points/s]\n"
     ]
    }
   ],
   "source": [
    "# | Run Nested Sampling\n",
    "dead = []\n",
    "with tqdm.tqdm(desc=\"Dead points\", unit=\" dead points\") as pbar:\n",
    "    #print(\"Starting Nested Sampling\")\n",
    "    #while not state.sampler_state.logZ_live - state.sampler_state.logZ < -3:\n",
    "    while not state.logZ_live - state.logZ < -3:\n",
    "        (state, rng_key), dead_info = one_step((state, rng_key), None)\n",
    "        dead.append(dead_info)\n",
    "        pbar.update(n_delete)  # Update progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating NestedSamples with 10 parameters: ['M_c', 'q', 's1_z', 's2_z', 'iota', 'd_L', 't_c', 'psi', 'ra', 'dec']\n",
      "Data shape: (23000, 10)\n",
      "LogL shape: (23000,)\n",
      "âœ… Saved nested samples to: test_refactor_v2.csv\n",
      "ðŸ“Š Summary:\n",
      "   - Sampled 10 parameters (phase_c marginalized)\n",
      "   - Total samples: 23000\n",
      "   - Evidence: logZ = 131.66\n",
      "   - Output file: test_refactor_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# Save nested sampling results using anesthetic\n",
    "from anesthetic import NestedSamples\n",
    "import numpy as np\n",
    "\n",
    "# Process dead points structure\n",
    "dead = jax.tree.map(\n",
    "    lambda *args: jnp.reshape(\n",
    "        jnp.stack(args, axis=0), (-1,) + args[0].shape[1:]\n",
    "    ),\n",
    "    *dead,\n",
    ")\n",
    "live = state\n",
    "\n",
    "# Combine log-likelihoods\n",
    "logL = np.concatenate((dead.loglikelihood, live.loglikelihood), dtype=float)\n",
    "logL_birth = np.concatenate((dead.loglikelihood_birth, live.loglikelihood_birth), dtype=float)\n",
    "# Where logL_birth is nan, set to -inf\n",
    "logL_birth = np.where(np.isnan(logL_birth), -np.inf, logL_birth)\n",
    "\n",
    "# Extract parameter data for ONLY the sampled parameters (in correct order)\n",
    "dead_data = np.column_stack([dead.particles[key] for key in SAMPLE_KEYS])\n",
    "live_data = np.column_stack([live.particles[key] for key in SAMPLE_KEYS])\n",
    "\n",
    "# Combine dead and live data\n",
    "data = np.concatenate([dead_data, live_data], axis=0)\n",
    "\n",
    "column_to_label = {\n",
    "    \"M_c\": r\"$M_c$\",\n",
    "    \"q\": r\"$q$\",\n",
    "    \"d_L\": r\"$d_L$\",\n",
    "    \"iota\": r\"$\\iota$\",\n",
    "    \"ra\": r\"$\\alpha$\",\n",
    "    \"dec\": r\"$\\delta$\",\n",
    "    \"s1_z\": r\"$s_{1z}$\",\n",
    "    \"s2_z\": r\"$s_{2z}$\",\n",
    "    \"t_c\": r\"$t_c$\",\n",
    "    \"psi\": r\"$\\psi$\",\n",
    "    \"phase_c\": r\"$\\phi_c$\",\n",
    "}\n",
    "\n",
    "# Create labels for sampled parameters only\n",
    "sampled_labels = {key: column_to_label[key] for key in SAMPLE_KEYS}\n",
    "\n",
    "print(f\"Creating NestedSamples with {len(SAMPLE_KEYS)} parameters: {SAMPLE_KEYS}\")\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"LogL shape: {logL.shape}\")\n",
    "\n",
    "# Create NestedSamples object\n",
    "samples = NestedSamples(\n",
    "    data, \n",
    "    logL=logL, \n",
    "    logL_birth=logL_birth, \n",
    "    columns=SAMPLE_KEYS,  # Only sampled parameters\n",
    "    labels=sampled_labels  # Only sampled parameter labels\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "output_filename = \"test_refactor_v2.csv\"\n",
    "samples.to_csv(output_filename)\n",
    "print(f\"âœ… Saved nested samples to: {output_filename}\")\n",
    "\n",
    "print(\"ðŸ“Š Summary:\")\n",
    "print(f\"   - Sampled {len(SAMPLE_KEYS)} parameters (phase_c marginalized)\")\n",
    "print(f\"   - Total samples: {data.shape[0]}\")\n",
    "print(f\"   - Evidence: logZ = {samples.logZ():.2f}\")\n",
    "print(f\"   - Output file: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'column_to_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m\n\u001b[1;32m     15\u001b[0m logL_birth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39misnan(logL_birth), \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, logL_birth)\n\u001b[1;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m     17\u001b[0m     [\n\u001b[1;32m     18\u001b[0m         np\u001b[38;5;241m.\u001b[39mcolumn_stack([v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m dead\u001b[38;5;241m.\u001b[39mparticles\u001b[38;5;241m.\u001b[39mvalues()]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m samples \u001b[38;5;241m=\u001b[39m NestedSamples(\n\u001b[0;32m---> 25\u001b[0m     data, logL\u001b[38;5;241m=\u001b[39mlogL, logL_birth\u001b[38;5;241m=\u001b[39mlogL_birth, columns\u001b[38;5;241m=\u001b[39mparticles\u001b[38;5;241m.\u001b[39mkeys(), labels\u001b[38;5;241m=\u001b[39m\u001b[43mcolumn_to_label\u001b[49m\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m samples\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphase_psi_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'column_to_label' is not defined"
     ]
    }
   ],
   "source": [
    "from anesthetic import NestedSamples\n",
    "import numpy as np\n",
    "\n",
    "dead = jax.tree.map(\n",
    "    lambda *args: jnp.reshape(\n",
    "        jnp.stack(args, axis=0), (-1,) + args[0].shape[1:]\n",
    "    ),\n",
    "    *dead,\n",
    ")\n",
    "live = state\n",
    "\n",
    "logL = np.concatenate((dead.loglikelihood, live.loglikelihood), dtype=float)\n",
    "logL_birth = np.concatenate((dead.loglikelihood_birth, live.loglikelihood_birth), dtype=float)\n",
    "#where logL_birth is nan, set to -inf\n",
    "logL_birth = np.where(np.isnan(logL_birth), -np.inf, logL_birth)\n",
    "data = np.concatenate(\n",
    "    [\n",
    "        np.column_stack([v for v in dead.particles.values()]),\n",
    "        np.column_stack([v for v in live.particles.values()]),\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "samples = NestedSamples(\n",
    "    data, logL=logL, logL_birth=logL_birth, columns=particles.keys(), labels=column_to_label\n",
    ")\n",
    "\n",
    "samples.to_csv(\"phase_psi_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
